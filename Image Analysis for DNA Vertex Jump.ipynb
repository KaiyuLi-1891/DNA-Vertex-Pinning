{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d54f0a-b811-4c7a-b98c-498e93463766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image analysis pipeline for DNA vertex jump under electric field reversal\n",
    "# Original : DNA stretched rightward before reversal and leftward after; Opposite: DNA stretched leftward before reversal and rightward after\n",
    "# The code directly uses raw TIFF files that have not been rotated. \n",
    "# The rightward direction in the figure corresponds to the downward direction in the imported TIFF files, and leftward in the figure corresponds to upward in the TIFF.\n",
    "\n",
    "import tifffile\n",
    "import numpy as np\n",
    "from scipy.spatial import KDTree\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.filters import frangi\n",
    "from scipy.ndimage import generic_filter, gaussian_filter1d\n",
    "from scipy.signal import find_peaks\n",
    "import math\n",
    "import os\n",
    "import csv\n",
    "import uuid\n",
    "from collections import defaultdict\n",
    "\n",
    "# ===== Parameters =====\n",
    "window_size = 9\n",
    "buffer_frame = 1\n",
    "max_shift_distance = 40.0 # Distance constraint when matching vertices\n",
    "max_angle = 15  # Angular constraint when matching vertices (within 15° of the streamwise direction)\n",
    "\n",
    "tiff_path_list = [r\"D:\\DNA data\\20250721\\REV\\20250731_1PVP_REV(4).tif\"]\n",
    "# Manually identified central frame of each reversal event \n",
    "frame_list_original = [[91, 291, 504]]\n",
    "frame_list_opposite = [[184, 378, 621]]\n",
    "\n",
    "all_matches_original = []\n",
    "all_matches_opposite = []\n",
    "\n",
    "params = {\n",
    "    'min_length': 40,        # Minimum DNA length in pixels (vertical)\n",
    "    'max_width': 8,         # Maximum DNA width in pixels\n",
    "}\n",
    "\n",
    "# ===== Functions =====\n",
    "def find_ends_by_morphology(image, direction=0):\n",
    "    \"\"\"Find DNA ends using morphology\"\"\"\n",
    "    # Edge detection\n",
    "    mean_val = np.mean(image)\n",
    "    std_val = np.std(image)\n",
    "    image_edges = cv2.Canny(image, int(mean_val), int(mean_val + 3 * std_val))\n",
    "    \n",
    "    potential_pinpoints = []\n",
    "    potential_ends = []\n",
    "    height, width = image.shape\n",
    "    \n",
    "    # Scan through image to find edge points\n",
    "    for py in range(1, height-1):\n",
    "        for px in range(1, width-1):\n",
    "            if image_edges[py, px] == 255 and image[py, px] > mean_val:\n",
    "                neighborhood = image_edges[py-1:py+2, px-1:px+2]\n",
    "\n",
    "                if direction == 0:\n",
    "                    # Top edge detection (for downward DNA)\n",
    "                    if np.all(neighborhood[0, :] == 0):  # Top edge\n",
    "                        potential_pinpoints.append((px, py))\n",
    "                    # Bottom edge detection (for upward DNA)\n",
    "                    elif np.all(neighborhood[2, :] == 0):  # Bottom edge\n",
    "                        potential_ends.append((px, py))\n",
    "                else:\n",
    "                    # Top edge detection (for downward DNA)\n",
    "                    if np.all(neighborhood[0, :] == 0):  # Top edge\n",
    "                        potential_ends.append((px, py))\n",
    "                    # Bottom edge detection (for upward DNA)\n",
    "                    elif np.all(neighborhood[2, :] == 0):  # Bottom edge\n",
    "                        potential_pinpoints.append((px, py))\n",
    "    \n",
    "    # Select pinpoints and ends\n",
    "    pinpoint = None\n",
    "    if potential_pinpoints:\n",
    "        # For downward DNA, pinpoint is topmost point\n",
    "        if direction == 0:\n",
    "            pinpoint = min(potential_pinpoints, key=lambda p: p[1])\n",
    "        else:\n",
    "            pinpoint = max(potential_pinpoints, key=lambda p: p[1])\n",
    "            \n",
    "    longend = None\n",
    "    if potential_ends:\n",
    "        if direction == 0:\n",
    "            # For downward DNA, longend is bottommost point\n",
    "            longend = max(potential_ends, key=lambda p: p[1])\n",
    "        else:\n",
    "            longend = min(potential_ends, key=lambda p: p[1])\n",
    "            \n",
    "    return np.array(pinpoint) if pinpoint else None, [], np.array(longend) if longend else None\n",
    "\n",
    "def check_overlap(image):\n",
    "    \"\"\"Check for overlapping DNA arms (vertical orientation)\"\"\"\n",
    "    count = 0\n",
    "    distance = 0\n",
    "    max_length = 0\n",
    "    cropped_image = image[:, :image.shape[1] - image.shape[1] % 3]\n",
    "    \n",
    "    for i in range(0, cropped_image.shape[1], 3):\n",
    "        col = np.sum(cropped_image[:, i:i+3], axis=1)\n",
    "        smoothed = gaussian_filter1d(col, sigma=1)\n",
    "        peaks, _ = find_peaks(smoothed, distance=3, height=np.mean(smoothed)*1.1)\n",
    "        \n",
    "        if len(peaks) == 2:\n",
    "            distance += abs(peaks[0] - peaks[1])\n",
    "            count += 1\n",
    "        else:\n",
    "            if count >= 3:\n",
    "                return True, distance/count, i\n",
    "            count = 0\n",
    "            distance = 0\n",
    "    \n",
    "    return False, 0, 0\n",
    "\n",
    "def find_ends(image, direction=0):\n",
    "    \"\"\"Find DNA ends in vertically oriented images\"\"\"\n",
    "    # Morphology-based detection\n",
    "    pinpoint_morph, _, longend_morph = find_ends_by_morphology(image, direction)\n",
    "    \n",
    "    # Intensity-based detection\n",
    "    mean_intensity = np.mean(image)\n",
    "    vertical_gradient = generic_filter(image, np.std, size=(1, 3))\n",
    "    vertical_profile = np.sum(vertical_gradient, axis=0)\n",
    "    vertical_smoothed = gaussian_filter1d(vertical_profile, sigma=1)\n",
    "    peaks, _ = find_peaks(vertical_smoothed)\n",
    "    \n",
    "    candidates = []\n",
    "    for px in peaks:\n",
    "        col = image[:, px]\n",
    "        py = np.argmax(col)\n",
    "        if col[py] > mean_intensity:\n",
    "            candidates.append((px, py))\n",
    "\n",
    "    if direction == 0:\n",
    "        pinpoint_intensity = min(candidates, key=lambda p: p[1]) if candidates else None\n",
    "        longend_intensity = max(candidates, key=lambda p: p[1]) if candidates else None\n",
    "    else:\n",
    "        pinpoint_intensity = max(candidates, key=lambda p: p[1]) if candidates else None\n",
    "        longend_intensity = min(candidates, key=lambda p: p[1]) if candidates else None\n",
    "        \n",
    "    # Combine results\n",
    "    potential_pinpoints = []\n",
    "    if pinpoint_morph is not None: \n",
    "        potential_pinpoints.append(pinpoint_morph)\n",
    "    if pinpoint_intensity is not None: \n",
    "        potential_pinpoints.append(pinpoint_intensity)\n",
    "    \n",
    "    potential_longends = []\n",
    "    if longend_morph is not None: \n",
    "        potential_longends.append(longend_morph)\n",
    "    if longend_intensity is not None: \n",
    "        potential_longends.append(longend_intensity)\n",
    "    \n",
    "    # Final selection \n",
    "    if direction == 0:\n",
    "        pinpoint = min(potential_pinpoints, key=lambda p: p[1]) if potential_pinpoints else None\n",
    "        longend = max(potential_longends, key=lambda p: p[1]) if potential_longends else None\n",
    "    else:\n",
    "        pinpoint = max(potential_pinpoints, key=lambda p: p[1]) if potential_pinpoints else None\n",
    "        longend = min(potential_longends, key=lambda p: p[1]) if potential_longends else None\n",
    "        \n",
    "    return pinpoint, None, longend\n",
    "\n",
    "def detect_pinpoints(median_image, params, direction=0):\n",
    "    \"\"\"Detect pinpoints in vertically oriented DNA images\"\"\"\n",
    "    # Preprocessing\n",
    "    processed = cv2.convertScaleAbs(median_image, alpha=2.0, beta=-200)\n",
    "    \n",
    "    # Processing pipeline\n",
    "    blurred = cv2.GaussianBlur(processed, (1, 15), 0)  # Vertical blur for vertical DNA\n",
    "    background = cv2.GaussianBlur(blurred, (25, 25), 0)\n",
    "    dog = cv2.subtract(blurred, background)\n",
    "    \n",
    "    # Frangi filtering for vertical structures\n",
    "    frangi_img = frangi(dog, np.linspace(1.0, 6.0, 12), alpha=0.3, beta=1.2, gamma=7.5, black_ridges=False)\n",
    "    thresholded = (frangi_img > 0.01).astype(np.uint8) * 255\n",
    "    \n",
    "    # Connected component analysis\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(thresholded)\n",
    "\n",
    "    print(\"Cropped Segmentation:\", num_labels)\n",
    "    \n",
    "    pinpoints = []\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h = stats[i, 0:4]\n",
    "        \n",
    "        # Filter based on vertical orientation\n",
    "        if (h > params['min_length'] and  # Height is now the length\n",
    "            w < params['max_width']):\n",
    "            \n",
    "            roi = dog[y:y+h, x:x+w]\n",
    "            pinpoint, _, longend = find_ends(roi, direction)\n",
    "            \n",
    "            if pinpoint is not None:\n",
    "                # Convert to global coordinates\n",
    "                global_coord = (x + pinpoint[0], y + pinpoint[1])\n",
    "                pinpoints.append(global_coord)\n",
    "    \n",
    "    return pinpoints\n",
    "\n",
    "def compute_window_median(image_stack, center_frame, position='before'):\n",
    "    \"\"\"Compute median image for before/after field change windows\"\"\"\n",
    "    if position == 'before':\n",
    "        start = max(0, center_frame - window_size - buffer_frame)\n",
    "        end = center_frame - buffer_frame\n",
    "    else:  # 'after'\n",
    "        start = center_frame + 1 + buffer_frame\n",
    "        end = min(center_frame + window_size + 1 + buffer_frame, len(image_stack))\n",
    "    \n",
    "    print(f\"Computing {position} median: frames {start} to {end-1}\")\n",
    "    return np.median(image_stack[start:end], axis=0)\n",
    "\n",
    "def match_pinpoints(points_bef, points_aft, max_distance, scenario, max_angle=15):\n",
    "    \"\"\"Match points with strict angular/directional constraints for high density\"\"\"\n",
    "    if not points_aft or not points_bef:\n",
    "        return [], points_bef, points_aft\n",
    "\n",
    "    # Convert to numpy arrays for efficient operations\n",
    "    bef_array = np.array(points_bef)\n",
    "    aft_array = np.array(points_aft)\n",
    "    \n",
    "    # Build spatial trees for fast queries\n",
    "    bef_tree = KDTree(bef_array)\n",
    "    aft_tree = KDTree(aft_array)\n",
    "    \n",
    "    # Generate candidate matches with directional validation\n",
    "    candidate_matches = []\n",
    "    for j, p_aft in enumerate(aft_array):\n",
    "        # Find all points within max distance\n",
    "        candidates_idx = bef_tree.query_ball_point(p_aft, max_distance)\n",
    "        \n",
    "        for i in candidates_idx:\n",
    "            p_bef = bef_array[i]\n",
    "            dx = p_aft[0] - p_bef[0]\n",
    "            dy = p_aft[1] - p_bef[1]\n",
    "            distance = math.sqrt(dx**2 + dy**2)\n",
    "            \n",
    "            # Skip near-zero displacements\n",
    "            if distance < 0.1:\n",
    "                continue\n",
    "                \n",
    "            # Calculate angular deviation from vertical streamwise direction (0° = vertical)\n",
    "            angle = math.degrees(math.acos(abs(dy) / distance))\n",
    "            \n",
    "            # Scenario-specific directional validation\n",
    "            if scenario == 'original':\n",
    "                valid_direction = (dy < 0)  # y decreases (bef below aft)\n",
    "            else:  # opposite\n",
    "                valid_direction = (dy > 0)  # y increases (bef above aft)\n",
    "                \n",
    "            # Include candidate if constraints met\n",
    "            if angle <= max_angle and valid_direction:\n",
    "                candidate_matches.append((i, j, angle, distance))\n",
    "    \n",
    "    # Group candidates by after point and select best (smallest angle)\n",
    "    best_candidates = {}\n",
    "    for i, j, angle, dist in candidate_matches:\n",
    "        if j not in best_candidates or angle < best_candidates[j][2]:\n",
    "            best_candidates[j] = (i, j, angle, dist)\n",
    "    \n",
    "    # Convert to list and sort by quality (angle then distance)\n",
    "    sorted_candidates = sorted(best_candidates.values(), key=lambda x: (x[2], x[3]))\n",
    "    \n",
    "    # Final matching with one-to-one constraint\n",
    "    matches = []\n",
    "    matched_bef = set()\n",
    "    matched_aft = set()\n",
    "    \n",
    "    for candidate in sorted_candidates:\n",
    "        i, j, angle, dist = candidate\n",
    "        if i not in matched_bef and j not in matched_aft:\n",
    "            matches.append((points_bef[i], points_aft[j]))\n",
    "            matched_bef.add(i)\n",
    "            matched_aft.add(j)\n",
    "    \n",
    "    # Identify unmatched points\n",
    "    unmatched_bef = [p for i, p in enumerate(points_bef) if i not in matched_bef]\n",
    "    unmatched_aft = [p for i, p in enumerate(points_aft) if i not in matched_aft]\n",
    "    \n",
    "    return matches, unmatched_bef, unmatched_aft\n",
    "\n",
    "# ===== MAIN PROCESSING LOOP =====\n",
    "for idx in range(len(tiff_path_list)):\n",
    "    tiff_path = tiff_path_list[idx]\n",
    "    tiff_filename = os.path.basename(tiff_path)\n",
    "    \n",
    "    print(f\"\\n{'#'*50}\")\n",
    "    print(f\"Processing: {tiff_filename}\")\n",
    "    print(f\"{'#'*50}\")\n",
    "    \n",
    "    # Load TIFF stack\n",
    "    with tifffile.TiffFile(tiff_path) as tif:\n",
    "        image_stack = tif.asarray()\n",
    "        print(f\"Loaded stack: {image_stack.shape} (frames, height, width)\")\n",
    "    \n",
    "    # Initialize per-file collections\n",
    "    file_matches_original = []\n",
    "    file_matches_opposite = []\n",
    "    \n",
    "    # ===== PROCESS ORIGINAL SCENARIO =====\n",
    "    print(\"\\nProcessing ORIGINAL scenario (down before, up after)\")\n",
    "    for cf in frame_list_original[idx]:\n",
    "        print(f\"\\n{'='*40}\")\n",
    "        print(f\"Processing frame {cf} (original scenario)\")\n",
    "        print(f\"{'='*40}\")\n",
    "        \n",
    "        # Compute medians\n",
    "        median_bef = compute_window_median(image_stack, cf, 'before')\n",
    "        median_aft = compute_window_median(image_stack, cf, 'after')\n",
    "        \n",
    "        # Detect pinpoints - original scenario\n",
    "        pinpoints_bef = detect_pinpoints(median_bef, params, direction=0)  # Down before (direction=0)\n",
    "        pinpoints_aft = detect_pinpoints(median_aft, params, direction=1)  # Up after (direction=1)\n",
    "        \n",
    "        # Match pinpoints with enhanced constraints\n",
    "        matched_pairs, _, _ = match_pinpoints(\n",
    "            pinpoints_bef, pinpoints_aft, max_shift_distance, \n",
    "            scenario='original', max_angle=max_angle\n",
    "        )\n",
    "        \n",
    "        # Store results\n",
    "        for pair in matched_pairs:\n",
    "            p_bef, p_aft = pair\n",
    "            point_id = str(uuid.uuid4())[:8]\n",
    "            match_data = {\n",
    "                'id': point_id,\n",
    "                'file': tiff_filename,\n",
    "                'frame': cf,\n",
    "                'x_before': p_bef[0],\n",
    "                'y_before': p_bef[1],\n",
    "                'x_after': p_aft[0],\n",
    "                'y_after': p_aft[1],\n",
    "                'status': 'matched',\n",
    "                'scenario': 'original',\n",
    "                'displacement': math.hypot(p_aft[0]-p_bef[0], p_aft[1]-p_bef[1])\n",
    "            }\n",
    "            file_matches_original.append(match_data)\n",
    "            all_matches_original.append(match_data)\n",
    "        \n",
    "        print(f\"Persistent molecules: {len(matched_pairs)}\")\n",
    "    \n",
    "    # ===== PROCESS OPPOSITE SCENARIO =====\n",
    "    print(\"\\nProcessing OPPOSITE scenario (up before, down after)\")\n",
    "    for cf in frame_list_opposite[idx]:\n",
    "        print(f\"\\n{'='*40}\")\n",
    "        print(f\"Processing frame {cf} (opposite scenario)\")\n",
    "        print(f\"{'='*40}\")\n",
    "        \n",
    "        # Compute medians\n",
    "        median_bef = compute_window_median(image_stack, cf, 'before')\n",
    "        median_aft = compute_window_median(image_stack, cf, 'after')\n",
    "        \n",
    "        # Detect pinpoints - opposite scenario\n",
    "        pinpoints_bef = detect_pinpoints(median_bef, params, direction=1)  # Up before (direction=1)\n",
    "        pinpoints_aft = detect_pinpoints(median_aft, params, direction=0)  # Down after (direction=0)\n",
    "        \n",
    "        # Match pinpoints with enhanced constraints\n",
    "        matched_pairs, _, _ = match_pinpoints(\n",
    "            pinpoints_bef, pinpoints_aft, max_shift_distance, \n",
    "            scenario='opposite', max_angle=max_angle\n",
    "        )\n",
    "        \n",
    "        # Store results\n",
    "        for pair in matched_pairs:\n",
    "            p_bef, p_aft = pair\n",
    "            point_id = str(uuid.uuid4())[:8]\n",
    "            match_data = {\n",
    "                'id': point_id,\n",
    "                'file': tiff_filename,\n",
    "                'frame': cf,\n",
    "                'x_before': p_bef[0],\n",
    "                'y_before': p_bef[1],\n",
    "                'x_after': p_aft[0],\n",
    "                'y_after': p_aft[1],\n",
    "                'status': 'matched',\n",
    "                'scenario': 'opposite',\n",
    "                'displacement': math.hypot(p_aft[0]-p_bef[0], p_aft[1]-p_bef[1])\n",
    "            }\n",
    "            file_matches_opposite.append(match_data)\n",
    "            all_matches_opposite.append(match_data)\n",
    "        \n",
    "        print(f\"Persistent molecules: {len(matched_pairs)}\")\n",
    "    \n",
    "    # ===== SAVE PER-FILE RESULTS =====\n",
    "    if file_matches_original:\n",
    "        output_file = f'matched_pairs_ORIGINAL_{os.path.splitext(tiff_filename)[0]}.csv'\n",
    "        with open(output_file, 'w', newline='') as csvfile:\n",
    "            fieldnames = ['id', 'file', 'frame', 'x_before', 'y_before', \n",
    "                          'x_after', 'y_after', 'status', 'scenario', 'displacement']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(file_matches_original)\n",
    "            print(f\"Saved ORIGINAL scenario matches to {output_file}\")\n",
    "    \n",
    "    if file_matches_opposite:\n",
    "        output_file = f'matched_pairs_OPPOSITE_{os.path.splitext(tiff_filename)[0]}.csv'\n",
    "        with open(output_file, 'w', newline='') as csvfile:\n",
    "            fieldnames = ['id', 'file', 'frame', 'x_before', 'y_before', \n",
    "                          'x_after', 'y_after', 'status', 'scenario', 'displacement']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(file_matches_opposite)\n",
    "            print(f\"Saved OPPOSITE scenario matches to {output_file}\")\n",
    "\n",
    "# ===== FINAL OUTPUT =====\n",
    "if all_matches_original:\n",
    "    csv_path = 'all_matched_pairs_ORIGINAL.csv'\n",
    "    with open(csv_path, 'w', newline='') as csvfile:\n",
    "        fieldnames = ['id', 'file', 'frame', 'x_before', 'y_before', \n",
    "                      'x_after', 'y_after', 'status', 'scenario', 'displacement']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(all_matches_original)\n",
    "    print(f\"\\nSaved all ORIGINAL scenario matches to: {csv_path}\")\n",
    "\n",
    "if all_matches_opposite:\n",
    "    csv_path = 'all_matched_pairs_OPPOSITE.csv'\n",
    "    with open(csv_path, 'w', newline='') as csvfile:\n",
    "        fieldnames = ['id', 'file', 'frame', 'x_before', 'y_before', \n",
    "                      'x_after', 'y_after', 'status', 'scenario', 'displacement']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(all_matches_opposite)\n",
    "    print(f\"\\nSaved all OPPOSITE scenario matches to: {csv_path}\")\n",
    "\n",
    "print(\"\\nProcessing complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
